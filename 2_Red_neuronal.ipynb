{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CarlosBaez11/Carlos_Baez_C/blob/main/2_Red_neuronal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Instalación de las librerías y paquetes "
      ],
      "metadata": {
        "id": "1IxMcN9qvZ1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instalamos la librería de Fiftyone para la visualización de los datos, y gdown para poder descargar archivos directamente desde Drive"
      ],
      "metadata": {
        "id": "YIRA36QhvduO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0LdopPULfTOw"
      },
      "outputs": [],
      "source": [
        "!pip install fiftyone\n",
        "!pip install gdown"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fIKUVI5LxLUr"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import fiftyone\n",
        "import gdown\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente celda no es necesario ejecutarla, porque la utilicé para almacenar la red neuronal en Drive conforme se iba entrenando"
      ],
      "metadata": {
        "id": "u0vjru6Nvu9q"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgglzyn6TTvK"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20tV6Rf23KcT"
      },
      "source": [
        "Ahora vamos a descargar el dataset de drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZ4qkGbZ3M1B"
      },
      "outputs": [],
      "source": [
        "gdown.download( 'https://drive.google.com/u/1/uc?id=1AT9bncPf5USGFdGj5vAv3hy_3QNSENRe&export=download', '/content/frutas.zip' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPpNZAEe3-23"
      },
      "source": [
        "Extraemos el contenido del archivo en zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtrPv23e4EUT"
      },
      "outputs": [],
      "source": [
        "!unzip /content/frutas.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABXvX2264N05"
      },
      "source": [
        "Con la librería de fiftyone vamos a visualizar el contenido de nuestro dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0OrPNUZ4U85"
      },
      "outputs": [],
      "source": [
        "dataset=fiftyone.Dataset.from_dir(dataset_dir='/content/content/datasetfrutas_filtrado', label_field='ground_truth',\n",
        "                                  name='Dataset_frutas11_', dataset_type=fiftyone.types.ImageClassificationDirectoryTree\n",
        "                                  )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eg23cq3R4-nU"
      },
      "outputs": [],
      "source": [
        "fiftyone.launch_app(dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LesuQgoc6L__"
      },
      "source": [
        "Hasta el momento hemos utilizado los datasets de Fiftyone para exportar, visualizar y realizar un filtrado a las imágenes. Ahora vamos a crear los datasets de Tensorflow para entrenar a la red neuronal.\n",
        "\n",
        "\n",
        "\n",
        "Después de probar varias veces la red neuronal con su conexión al PLC, obtuvimos un mejor rendimiento con un tamaño de imagen de 360*360"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m1TnWzgAyBMu"
      },
      "outputs": [],
      "source": [
        "IMG_SIZE=(360,360)\n",
        "BATCH_SIZE=64\n",
        "IMG_SHAPE=IMG_SIZE+(3,)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h_T5ewEJyXiw"
      },
      "source": [
        "Ahora vamos a crear los datasets de entrenamiento y de validacion. En este caso vamos a utilizar la clase de datasets de Tensorflow, utilizando ocomo metodo de obtencion del dataset load/_image_dataset_from_directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x-Jw0yTiySIR"
      },
      "outputs": [],
      "source": [
        "#Vamos a crear el dataset de entrenamiento\n",
        "ds_training=keras.utils.image_dataset_from_directory('/content/content/datasetfrutas_filtrado', labels='inferred',\n",
        "                                                     label_mode='int', batch_size=BATCH_SIZE, shuffle=True, validation_split=0.2, image_size=IMG_SIZE, subset='training', seed=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWP2U--G2McY"
      },
      "outputs": [],
      "source": [
        "ds_test=keras.utils.image_dataset_from_directory('/content/content/datasetfrutas_filtrado',\n",
        "                                                 labels='inferred', label_mode='int', batch_size=BATCH_SIZE, shuffle=True, validation_split=0.2, image_size=IMG_SIZE, subset='validation', seed=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que esta red neronal fue puesta en producción, consideramos necesario crear un Dataframe con las clases que contiene el dataset con el que fue entrenada, para posteriormente exportarlo como un CSV y mapear el resultado de las predicciones con el nombre correspondiente a cada fruta"
      ],
      "metadata": {
        "id": "JMfGtJoxwjpN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NvKgMEE3PcP"
      },
      "outputs": [],
      "source": [
        "class_names=ds_training.class_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQkxSomdwEpR"
      },
      "outputs": [],
      "source": [
        "classes=pd.DataFrame(class_names)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DWa_q1nwRo1"
      },
      "outputs": [],
      "source": [
        "classes.to_csv('/content/classes.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XGIr3ku2UEl"
      },
      "source": [
        "Ahora vamos a visuzalizar los datos del dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfowQvYu2Uut"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for images, labels in ds_training.take(1):\n",
        "  for i in range (9):\n",
        "    ax=plt.subplot(3,3,i+1)\n",
        "    plt.imshow(images[i].numpy().astype('uint8'))\n",
        "    plt.title(class_names[labels[i]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yusflhri3jbo"
      },
      "source": [
        "Con el propósito de reducir timepo de entrenamiento en la medida de lo posible, y poder realizar cambios en la arquitectura rápidamente, vamos a aplicar transfer learning. Por tanto, descargamos los pesos de la arquitectura. En este caso seleccionamos la arquitectura VGG 16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtJflxFT3uuJ"
      },
      "outputs": [],
      "source": [
        "base_model=keras.applications.VGG19(include_top=False, input_shape=IMG_SHAPE,pooling='avg', classifier_activation=False, weights='imagenet' )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEfLDRey4T8N"
      },
      "source": [
        "Ahora tenemos que congelar los pesos del modelos para evitar que durante la primera etapa del entrenamiento de las capas densas se pierdan las caracteristicas preentrenadas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IRYaahoA4goX"
      },
      "outputs": [],
      "source": [
        "for i in base_model.layers:\n",
        "  i.trainable=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lI8pnbPs4oAQ"
      },
      "source": [
        "Ahora que tenemos el modelo congelado, vamos a crear la arquitectura de la red neuronal con la API funcional de Keras. Vamos a añadir algunas capas para aumentar la cantidad de los datos, después van a ser enviados al modelo preentrenado, y la salida de este modelo alimentará las capas densas de clasificación para obtener la clase correspondiente de cada imagen.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xkOdZoP75qFh"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DVLAKoRW4uB-"
      },
      "outputs": [],
      "source": [
        "input=keras.Input(shape=IMG_SHAPE)\n",
        "\n",
        "\n",
        "#Utilizamos Data augmentation para aumentar la cantidad de datos de entrenamiento\n",
        "x=keras.layers.Resizing(IMG_SIZE[0], IMG_SIZE[1])(input)\n",
        "\n",
        "x=keras.layers.RandomZoom(0.5,0.5)(x)\n",
        "\n",
        "x=keras.layers.RandomContrast(1)(x)\n",
        "\n",
        "x=keras.layers.RandomCrop(IMG_SIZE[0], IMG_SIZE[1])(x)\n",
        "\n",
        "x=keras.layers.RandomFlip()(x)\n",
        "\n",
        "x=keras.layers.RandomRotation(255)(x)\n",
        "\n",
        "x=keras.applications.vgg19.preprocess_input(x)\n",
        "\n",
        "x=base_model(x)\n",
        "\n",
        "x=keras.layers.Flatten()(x)\n",
        "\n",
        "x=keras.layers.Dense(128, activation='selu', kernel_initializer='he_normal', kernel_regularizer=keras.regularizers.L1L2(l1=0.01, l2=0.01), use_bias=False)(x)\n",
        "\n",
        "outputs=keras.layers.Dense(len(class_names), activation='Softmax', kernel_initializer='glorot_normal' )(x)\n",
        "\n",
        "model=keras.Model(inputs=input, outputs=outputs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora con el método de Summary vemos algunas de las características del modelo que definimos"
      ],
      "metadata": {
        "id": "LdKB5gl8e9JI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAM5fC445wfk"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2iw55yKRUTaI"
      },
      "source": [
        "Creamos dos callbacks para poder interactuar con la red neuronal durante el entrenamiento. Usamos uno de ellos, que va a guardar el progreso del entrenamiento durante cada época, pero se encuentra comentado, dado que lo estaba guardando directamente en mi carpeta de Drive, por tanto, no es necesario ejecutarlo. El otro callback se encargar de para el entrenamiento cuando está detectando overfitting en los datos de entrenamiento."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSwFhQXY59ig"
      },
      "outputs": [],
      "source": [
        "# cb=keras.callbacks.ModelCheckpoint(filepath='/content/drive/MyDrive/red4.h5', save_freq='epoch') #No es necesario ejecutar esta celda\n",
        "\n",
        "cb1=keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con las configuraciones realizadas en el modelo, podemos compilarlo"
      ],
      "metadata": {
        "id": "4OLYURnYy3tC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dnnLHudr52Ib"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['acc'])"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora aplicamos el método de .fit() para entrenar el modelo. Dado que es solo la primera etapa del entrenamiento, lo vamos a entrenar como máximo durante 15 epocas"
      ],
      "metadata": {
        "id": "2NSBG7vBy8or"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJ036rzJ57qa"
      },
      "outputs": [],
      "source": [
        "model.fit(ds_training, batch_size=BATCH_SIZE, epochs=15, validation_data=ds_test, callbacks=[cb1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUDQ38x6JHfu"
      },
      "source": [
        "Ahora vamos a aplicar un Fine tunning para mejorar el desempeño del modelo. En esta etapa entrenaremos el modelo totalmente, pero con una tasa de aprendizaje muy baja, de tal forma que se le de un ligero ajuste que permita una mejora sustancial en la capacidad de predicción."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qE_oPidAJOCJ"
      },
      "outputs": [],
      "source": [
        "for i in model.layers:\n",
        "  i.trainable=True"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Verificamos que se puedan entrenar los peso del modelo observando sus atributos "
      ],
      "metadata": {
        "id": "sT-DdkDbze43"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FU1qzc5vJgaV"
      },
      "outputs": [],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7vYQ0MdZjHA"
      },
      "source": [
        "Para el fine tunning vamos a utilizar el mismo dataset, pero cambiando los datos de entrenamiento y de testeo para evitar el overfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "039E425ESr-w"
      },
      "outputs": [],
      "source": [
        "#Vamos a crear el dataset de entrenamiento\n",
        "ds_training=keras.utils.image_dataset_from_directory('/content/content/datasetfrutas_filtrado', labels='inferred',\n",
        "                                                     label_mode='int', batch_size=BATCH_SIZE, shuffle=True, validation_split=0.2, image_size=IMG_SIZE, subset='training', seed=40)\n",
        "ds_test=keras.utils.image_dataset_from_directory('/content/content/datasetfrutas_filtrado',\n",
        "                                                 labels='inferred', label_mode='int', batch_size=BATCH_SIZE, shuffle=True, validation_split=0.2, image_size=IMG_SIZE, subset='validation', seed=40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1RCtS1DbJmVd"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bsOqqDyBJx__"
      },
      "outputs": [],
      "source": [
        "model.fit(ds_training, batch_size=BATCH_SIZE, epochs=20, validation_data=ds_test, callbacks=[cb1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "provenance": [],
      "private_outputs": true,
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}